{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad8e5196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-----+--------+---------+-------------------+\n",
      "|order_id|user_id|price|quantity|status   |timestamp          |\n",
      "+--------+-------+-----+--------+---------+-------------------+\n",
      "|100101  |111    |9.8  |10      |Cancelled|08/17/2022 12:00:00|\n",
      "|100102  |111    |10.0 |10      |Completed|08/17/2022 12:00:00|\n",
      "|100259  |148    |5.1  |35      |Completed|08/25/2022 12:00:00|\n",
      "|100264  |148    |4.8  |40      |Completed|08/26/2022 12:00:00|\n",
      "|100305  |300    |10.0 |15      |Completed|09/05/2022 12:00:00|\n",
      "|100400  |178    |9.9  |15      |Completed|09/09/2022 12:00:00|\n",
      "|100565  |265    |25.6 |5       |Completed|12/19/2022 12:00:00|\n",
      "+--------+-------+-----+--------+---------+-------------------+\n",
      "\n",
      "+-------+-------------+-----------------------------+-------------------+\n",
      "|user_id|city         |email                        |signup_date        |\n",
      "+-------+-------------+-----------------------------+-------------------+\n",
      "|111    |San Francisco|rrok10@gmail.com             |08/03/2021 12:00:00|\n",
      "|148    |Boston       |sailor9820@gmail.com         |08/20/2021 12:00:00|\n",
      "|178    |San Francisco|harrypotterfan182@gmail.com  |01/05/2022 12:00:00|\n",
      "|265    |Denver       |shadower_@hotmail.com        |02/26/2022 12:00:00|\n",
      "|300    |San Francisco|houstoncowboy1122@hotmail.com|06/30/2022 12:00:00|\n",
      "+-------+-------------+-----------------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trades_df: org.apache.spark.sql.DataFrame = [order_id: int, user_id: int ... 4 more fields]\n",
       "users_df: org.apache.spark.sql.DataFrame = [user_id: int, city: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Assume you're given the tables containing completed trade orders and user details in a Robinhood trading system.\n",
    "\n",
    "// Write a query to retrieve the top three cities that have the highest number of completed trade orders listed in descending order. \n",
    "// Output the city name and the corresponding number of completed trade orders.\n",
    "\n",
    "// Example Output:\n",
    "// ----------------|--------------\n",
    "// city            |  total_orders\n",
    "// ----------------|---------------\n",
    "// San Francisco   |      3\n",
    "// Boston          |      2\n",
    "// Denver          |      1\n",
    "\n",
    "\n",
    "\n",
    "val trades_df = Seq(\n",
    "  (100101,111,9.80,10,\"Cancelled\",\"08/17/2022 12:00:00\"),\n",
    "  (100102,111,10.00,10,\"Completed\",\"08/17/2022 12:00:00\"),\n",
    "  (100259,148,5.10,35,\"Completed\",\"08/25/2022 12:00:00\"),\n",
    "  (100264,148,4.80,40,\"Completed\",\"08/26/2022 12:00:00\"),\n",
    "  (100305,300,10.00,15,\"Completed\",\"09/05/2022 12:00:00\"),\n",
    "  (100400,178,9.90,15,\"Completed\",\"09/09/2022 12:00:00\"),\n",
    "  (100565,265,25.60,5,\"Completed\",\"12/19/2022 12:00:00\")\n",
    ").toDF(\"order_id\",\"user_id\",\"price\",\"quantity\",\"status\",\"timestamp\")\n",
    "\n",
    "\n",
    "val users_df = Seq(\n",
    "  (111,\"San Francisco\",\"rrok10@gmail.com\",\"08/03/2021 12:00:00\"),\n",
    "  (148,\"Boston\",\"sailor9820@gmail.com\",\"08/20/2021 12:00:00\"),\n",
    "  (178,\"San Francisco\",\"harrypotterfan182@gmail.com\",\"01/05/2022 12:00:00\"),\n",
    "  (265,\"Denver\",\"shadower_@hotmail.com\",\"02/26/2022 12:00:00\"),\n",
    "  (300,\"San Francisco\",\"houstoncowboy1122@hotmail.com\",\"06/30/2022 12:00:00\")\n",
    ").toDF(\"user_id\",\"city\",\"email\",\"signup_date\")\n",
    "\n",
    "\n",
    "trades_df.show(false)\n",
    "users_df.show(false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c69424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- TakeOrderedAndProject(limit=3, orderBy=[total_orders#360L DESC NULLS LAST], output=[city#139,total_orders#360L])\n",
      "   +- HashAggregate(keys=[city#139], functions=[count(1)])\n",
      "      +- Exchange hashpartitioning(city#139, 200), ENSURE_REQUIREMENTS, [plan_id=448]\n",
      "         +- HashAggregate(keys=[city#139], functions=[partial_count(1)])\n",
      "            +- Project [city#139]\n",
      "               +- BroadcastHashJoin [user_id#114], [user_id#138], LeftOuter, BuildRight, false\n",
      "                  :- LocalTableScan [user_id#114]\n",
      "                  +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=443]\n",
      "                     +- LocalTableScan [user_id#138, city#139]\n",
      "\n",
      "\n",
      "+-------------+------------+\n",
      "|city         |total_orders|\n",
      "+-------------+------------+\n",
      "|San Francisco|3           |\n",
      "|Boston       |2           |\n",
      "|Denver       |1           |\n",
      "+-------------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [city: string, total_orders: bigint]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Using Dataframe API\n",
    "\n",
    "val df1 = trades_df.as(\"t\").join(users_df.as(\"u\"), $\"t.user_id\" === $\"u.user_id\", \"left\"\n",
    "                                ).where($\"t.status\" === \"Completed\"\n",
    "                                       ).groupBy($\"u.city\").agg(count($\"t.order_id\").as(\"total_orders\")\n",
    "                                                               ).orderBy($\"total_orders\".desc).limit(3)\n",
    "df1.explain()\n",
    "df1.show(false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e16aeb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- TakeOrderedAndProject(limit=3, orderBy=[total_orders#376L DESC NULLS LAST], output=[city#139,total_orders#376L])\n",
      "   +- HashAggregate(keys=[city#139], functions=[count(1)])\n",
      "      +- Exchange hashpartitioning(city#139, 200), ENSURE_REQUIREMENTS, [plan_id=597]\n",
      "         +- HashAggregate(keys=[city#139], functions=[partial_count(1)])\n",
      "            +- Project [city#139]\n",
      "               +- BroadcastHashJoin [user_id#114], [user_id#138], LeftOuter, BuildRight, false\n",
      "                  :- LocalTableScan [user_id#114]\n",
      "                  +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=592]\n",
      "                     +- LocalTableScan [user_id#138, city#139]\n",
      "\n",
      "\n",
      "+-------------+------------+\n",
      "|city         |total_orders|\n",
      "+-------------+------------+\n",
      "|San Francisco|3           |\n",
      "|Boston       |2           |\n",
      "|Denver       |1           |\n",
      "+-------------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [city: string, total_orders: bigint]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Using SPARK SQL\n",
    "\n",
    "trades_df.createOrReplaceTempView(\"trades\")\n",
    "users_df.createOrReplaceTempView(\"users\")\n",
    "\n",
    "val df2 = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        u.city,\n",
    "        COUNT(t.order_id) total_orders\n",
    "    FROM trades t \n",
    "    LEFT JOIN users u\n",
    "    ON t.user_id=u.user_id\n",
    "    WHERE status='Completed'\n",
    "    GROUP BY u.city\n",
    "    ORDER BY total_orders DESC\n",
    "    LIMIT 3\n",
    "\"\"\")\n",
    "\n",
    "df2.explain()\n",
    "df2.show(false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81831363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
